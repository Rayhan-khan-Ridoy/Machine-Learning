{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   807.41  535.57  161.72  182.65  170.32  861.78  494.26  221.65  143.26  \\\n",
      "0  161.72  182.65  807.41  535.57  170.32  861.78  494.26  221.65  143.26   \n",
      "1  170.32  861.78  807.41  535.57  161.72  182.65  494.26  221.65  143.26   \n",
      "2  494.26  221.65  807.41  535.57  161.72  182.65  170.32  861.78  143.26   \n",
      "3  143.26  476.72  807.41  535.57  161.72  182.65  170.32  861.78  494.26   \n",
      "4  449.64  653.16  807.41  535.57  161.72  182.65  170.32  861.78  494.26   \n",
      "\n",
      "   476.72  449.64  653.16  744.14  858.3  840.38  229.76  3  \n",
      "0  476.72  449.64  653.16  744.14  858.3  840.38  229.76  1  \n",
      "1  476.72  449.64  653.16  744.14  858.3  840.38  229.76  3  \n",
      "2  476.72  449.64  653.16  744.14  858.3  840.38  229.76  3  \n",
      "3  221.65  449.64  653.16  744.14  858.3  840.38  229.76  2  \n",
      "4  221.65  143.26  476.72  744.14  858.3  840.38  229.76  1  \n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('Dataset_UAV_8_12_24/datasetUAV8.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "X=np.asarray(X)\n",
    "y=np.asarray(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=101,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[886.7  242.19 154.64 ... 569.98 503.27 139.95]\n",
      " [146.73 204.47 561.66 ... 557.18 847.25 198.07]\n",
      " [167.11 801.2  838.14 ... 888.58 823.29 193.69]\n",
      " ...\n",
      " [214.26 808.84 849.91 ... 285.01 134.94 429.36]\n",
      " [532.35 360.83 489.5  ... 845.44 837.85 827.71]\n",
      " [264.66 879.66 843.37 ... 179.37 740.44 858.76]]\n",
      "[2 1 3 ... 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB_model = GaussianNB()\n",
    "SVC_model=svm.SVC()\n",
    "LogisticR_model=LogisticRegression(random_state=101)  \n",
    "KNN_model=KNeighborsClassifier(n_neighbors=5)\n",
    "Dtree_model=DecisionTreeClassifier()\n",
    "Random_model=RandomForestClassifier(n_estimators=10)\n",
    "XGBOOST_model=xgb.XGBClassifier(objective='binary:logistic',seed=101)\n",
    "GRADIENT_model=GradientBoostingClassifier(n_estimators=10, learning_rate=1.0,max_depth=1, random_state=101)\n",
    "ADABOOST_model=AdaBoostClassifier(n_estimators=10,learning_rate=1)\n",
    "BAGGINGBOOST_model = BaggingClassifier(base_estimator=SVC(),n_estimators=10, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHJ\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:25:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(), random_state=101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNB_model.fit(X_train,y_train)\n",
    "SVC_model.fit(X_train,y_train)\n",
    "LogisticR_model.fit(X_train,y_train)\n",
    "KNN_model.fit(X_train,y_train)\n",
    "Dtree_model.fit(X_train,y_train)\n",
    "Random_model.fit(X_train,y_train)\n",
    "XGBOOST_model.fit(X_train,y_train)\n",
    "GRADIENT_model.fit(X_train,y_train)\n",
    "ADABOOST_model.fit(X_train,y_train)\n",
    "BAGGINGBOOST_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB_prediction=GNB_model.predict(X_test)\n",
    "SVC_prediction=SVC_model.predict(X_test)\n",
    "LogisticR_prediction=LogisticR_model.predict(X_test)\n",
    "KNN_prediction=KNN_model.predict(X_test)\n",
    "Dtree_prediction=Dtree_model.predict(X_test)\n",
    "Random_prediction=Random_model.predict(X_test)\n",
    "XGBOOST_prediction=XGBOOST_model.predict(X_test)\n",
    "GRADIENT_prediction=GRADIENT_model.predict(X_test)\n",
    "ADABOOST_prediction=ADABOOST_model.predict(X_test)\n",
    "BAGGINGBOOST_prediction=BAGGINGBOOST_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.400125\n",
      "0.6854759615384616\n",
      "0.39065865384615384\n",
      "0.7366730769230769\n",
      "0.6824134615384615\n",
      "0.7457355769230769\n",
      "0.7496057692307693\n",
      "0.43623076923076926\n",
      "0.41215865384615386\n",
      "0.6861682692307692\n",
      "[[41381 28269 26565]\n",
      " [14894 18492 15631]\n",
      " [17356 22059 23353]]\n",
      "[[62945 10978  9536]\n",
      " [ 4892 37013 13392]\n",
      " [ 5794 20829 42621]]\n",
      "[[42828 31609 29707]\n",
      " [15663 17242 14655]\n",
      " [15140 19969 21187]]\n",
      "[[65824  7224  6994]\n",
      " [ 4705 46265 17416]\n",
      " [ 3102 15331 41139]]\n",
      "[[59356  7067  6681]\n",
      " [ 7361 42778 19060]\n",
      " [ 6914 18975 39808]]\n",
      "[[65345  6746  6421]\n",
      " [ 4538 49246 18606]\n",
      " [ 3748 12828 40522]]\n",
      "[[64960  7060  7064]\n",
      " [ 4766 46269 13796]\n",
      " [ 3905 15491 44689]]\n",
      "[[40574 22217 23459]\n",
      " [16473 26728 18656]\n",
      " [16584 19875 23434]]\n",
      "[[40540 25218 26850]\n",
      " [15298 25036 18546]\n",
      " [17793 18566 20153]]\n",
      "[[63140 11046  9649]\n",
      " [ 4854 37559 13876]\n",
      " [ 5637 20215 42024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.43      0.49     96215\n",
      "           2       0.27      0.38      0.31     49017\n",
      "           3       0.36      0.37      0.36     62768\n",
      "\n",
      "    accuracy                           0.40    208000\n",
      "   macro avg       0.40      0.39      0.39    208000\n",
      "weighted avg       0.43      0.40      0.41    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.75      0.80     83459\n",
      "           2       0.54      0.67      0.60     55297\n",
      "           3       0.65      0.62      0.63     69244\n",
      "\n",
      "    accuracy                           0.69    208000\n",
      "   macro avg       0.68      0.68      0.68    208000\n",
      "weighted avg       0.70      0.69      0.69    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.41      0.48    104144\n",
      "           2       0.25      0.36      0.30     47560\n",
      "           3       0.32      0.38      0.35     56296\n",
      "\n",
      "    accuracy                           0.39    208000\n",
      "   macro avg       0.39      0.38      0.38    208000\n",
      "weighted avg       0.44      0.39      0.40    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.82      0.86     80042\n",
      "           2       0.67      0.68      0.67     68386\n",
      "           3       0.63      0.69      0.66     59572\n",
      "\n",
      "    accuracy                           0.74    208000\n",
      "   macro avg       0.73      0.73      0.73    208000\n",
      "weighted avg       0.74      0.74      0.74    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.81      0.81     73104\n",
      "           2       0.62      0.62      0.62     69199\n",
      "           3       0.61      0.61      0.61     65697\n",
      "\n",
      "    accuracy                           0.68    208000\n",
      "   macro avg       0.68      0.68      0.68    208000\n",
      "weighted avg       0.68      0.68      0.68    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.83      0.86     78512\n",
      "           2       0.72      0.68      0.70     72390\n",
      "           3       0.62      0.71      0.66     57098\n",
      "\n",
      "    accuracy                           0.75    208000\n",
      "   macro avg       0.74      0.74      0.74    208000\n",
      "weighted avg       0.75      0.75      0.75    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.82      0.85     79084\n",
      "           2       0.67      0.71      0.69     64831\n",
      "           3       0.68      0.70      0.69     64085\n",
      "\n",
      "    accuracy                           0.75    208000\n",
      "   macro avg       0.75      0.74      0.74    208000\n",
      "weighted avg       0.76      0.75      0.75    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.47      0.51     86250\n",
      "           2       0.39      0.43      0.41     61857\n",
      "           3       0.36      0.39      0.37     59893\n",
      "\n",
      "    accuracy                           0.44    208000\n",
      "   macro avg       0.43      0.43      0.43    208000\n",
      "weighted avg       0.45      0.44      0.44    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.44      0.49     92608\n",
      "           2       0.36      0.43      0.39     58880\n",
      "           3       0.31      0.36      0.33     56512\n",
      "\n",
      "    accuracy                           0.41    208000\n",
      "   macro avg       0.41      0.41      0.40    208000\n",
      "weighted avg       0.43      0.41      0.42    208000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.75      0.80     83835\n",
      "           2       0.55      0.67      0.60     56289\n",
      "           3       0.64      0.62      0.63     67876\n",
      "\n",
      "    accuracy                           0.69    208000\n",
      "   macro avg       0.68      0.68      0.68    208000\n",
      "weighted avg       0.70      0.69      0.69    208000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(GNB_prediction,y_test))\n",
    "print(accuracy_score(SVC_prediction,y_test))\n",
    "print(accuracy_score(LogisticR_prediction,y_test))\n",
    "print(accuracy_score(KNN_prediction,y_test))\n",
    "print(accuracy_score(Dtree_prediction,y_test))\n",
    "print(accuracy_score(Random_prediction,y_test))\n",
    "print(accuracy_score(XGBOOST_prediction,y_test))\n",
    "print(accuracy_score(GRADIENT_prediction,y_test))\n",
    "print(accuracy_score(ADABOOST_prediction,y_test))\n",
    "print(accuracy_score(BAGGINGBOOST_prediction,y_test))\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(GNB_prediction,y_test))\n",
    "print(confusion_matrix(SVC_prediction,y_test))\n",
    "print(confusion_matrix(LogisticR_prediction,y_test))\n",
    "print(confusion_matrix(KNN_prediction,y_test))\n",
    "print(confusion_matrix(Dtree_prediction,y_test))\n",
    "print(confusion_matrix(Random_prediction,y_test))\n",
    "print(confusion_matrix(XGBOOST_prediction,y_test))\n",
    "print(confusion_matrix(GRADIENT_prediction,y_test))\n",
    "print(confusion_matrix(ADABOOST_prediction,y_test))\n",
    "print(confusion_matrix(BAGGINGBOOST_prediction,y_test))\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(GNB_prediction,y_test)) \n",
    "print(classification_report(SVC_prediction,y_test))\n",
    "print(classification_report(LogisticR_prediction,y_test))\n",
    "print(classification_report(KNN_prediction,y_test))\n",
    "print(classification_report(Dtree_prediction,y_test))\n",
    "print(classification_report(Random_prediction,y_test))\n",
    "print(classification_report(XGBOOST_prediction,y_test))\n",
    "print(classification_report(GRADIENT_prediction,y_test))\n",
    "print(classification_report(ADABOOST_prediction,y_test))\n",
    "print(classification_report(BAGGINGBOOST_prediction,y_test))\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
